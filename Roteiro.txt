Roteiro da Apresentação: AV2 de IA (Banknote Authentication)

Este documento contém os tópicos para cada slide e as notas do apresentador (roteiro de fala) para cada seção obrigatória do trabalho.

1. Introdução (3-5 minutos)

Tópicos do Slide

Título: Classificação de Cédulas Falsas com KNN e Naive Bayes

Problema de Negócio:

A necessidade de detecção automática de notas falsas em caixas eletrônicos e pontos de venda.

Objetivo: Criar um modelo de Machine Learning de alta precisão para classificar cédulas como "Genuínas" (Classe 0) ou "Falsas" (Classe 1).

O Dataset: Banknote Authentication (UCI)

Origem: 1372 amostras extraídas de imagens 400x400 de notas.

Atributos (Features): 4 preditores contínuos, extraídos via Transformada Wavelet:

variance (Variância)

skewness (Assimetria)

curtosis (Curtose)

entropy (Entropia)

Classes (Alvo): 2 classes (762 Genuínas, 610 Falsas).

Modelos Implementados (Do Zero):

K-Nearest Neighbors (KNN)

Naive Bayes Gaussiano (Univariado)

Bayesiano Gaussiano (Multivariado)

Metodologia de Avaliação:

Validação Cruzada 10-Fold Estratificada

Métricas: Acurácia, Precisão (Macro) e F1-Score (Macro).

Restrição: Sem sklearn ou pandas; apenas NumPy.

Notas do Apresentador (Roteiro)

(Início)
"Bom dia, [professor/professora/colegas]. Hoje vou apresentar o trabalho da AV2, que consiste em implementar e avaliar três classificadores do zero para o problema de autenticação de cédulas."

"O problema de negócio é muito claro: a detecção de notas falsas é crucial para a segurança financeira. Nosso objetivo é construir um modelo que possa, automaticamente, classificar uma nota como genuína ou falsa com base em características estatísticas extraídas de sua imagem."

"Para isso, usamos o dataset 'Banknote Authentication' da UCI. Ele tem 1372 amostras, divididas em 4 atributos preditores: variância, assimetria, curtose e entropia da imagem. O dataset é bem balanceado, com 762 notas genuínas e 610 falsas."

"Os requisitos do trabalho eram implementar três modelos do zero, sem usar bibliotecas como Scikit-learn: o KNN, com duas métricas de distância; o Naive Bayes Univariado, que assume que os atributos são independentes; e o Bayesiano Multivariado, que modela a correlação entre os atributos."

"Finalmente, a metodologia de avaliação foi uma Validação Cruzada 10-fold Estratificada, para garantir que cada fold de teste tivesse a mesma proporção de notas falsas e verdadeiras, e avaliamos os modelos usando Acurácia, Precisão Macro e F1-Score Macro."
(Fim)

2. Explicação do Código (3-5 minutos)

Tópicos do Slide

Arquitetura do Projeto:

main.py: Ponto de entrada, responsável pela interface (CLI) e orquestração.

data/: Pasta para o dataset CSV.

src/: Contém toda a lógica de programação.

Módulos Principais (Dentro de src/):

carregar_data.py: Lê o CSV puro (sem pandas) e o converte para arrays NumPy X e y.

metricas.py: Implementação manual da Matriz de Confusão, Acurácia, Precisão Macro e F1 Macro (com proteção contra divisão por zero).

utils.py: Contém o NormalizadorPadrao (Z-score) e os "testes de sanidade" (sanity checks) que validam nossos algoritmos antes da execução.

modelo_*.py: (knn, bayes_uni, bayes_multi) Classes que implementam a lógica de fit e predict de cada algoritmo.

timing.py: Um decorador @medir_tempo que injeta os atributos .tempo_treino_ e .tempo_teste_ nos modelos.

cv.py: O "coração" do projeto.

Destaque: cv.py (Validação Cruzada)

_gerar_indices_folds_estratificados: Nossa implementação manual do StratifiedKFold.

_selecionar_melhor_k: Realiza uma sub-validação (3-fold) dentro do treino para encontrar o K ótimo para o KNN (baseado no F1-Score).

validacao_cruzada: O loop principal que treina, testa, normaliza e coleta os 10 resultados para todos os classificadores.

Notas do Apresentador (Roteiro)

(Início)
"Para organizar o projeto, seguimos uma estrutura modular. O main.py fica na raiz e apenas orquestra a execução. Toda a lógica de implementação reside na pasta src/."

"Dentro da src/, temos módulos bem definidos: carregar_data.py usa o módulo csv nativo do Python para ler os dados. metricas.py implementa do zero as métricas macro, calculando VP, FP e FN por classe e depois tirando a média, como solicitado."

"O utils.py é importante, pois contém não só o nosso Normalizador Z-score, mas também uma suíte de 'testes de sanidade'. Antes de rodar o pipeline, esses testes verificam com dados sintéticos se o KNN, o Bayes Uni e o Bayes Multi estão calculando médias, covariâncias e predições corretamente. Isso foi crucial para debugar o projeto."

"Cada modelo tem sua própria classe em modelo_*.py, e o timing.py nos deu um decorador simples para medir o tempo exato de fit e predict separadamente."

"O módulo mais complexo é o cv.py. Ele é responsável por três coisas: primeiro, gerar os 10 folds estratificados manualmente, garantindo a proporção das classes; segundo, orquestrar o loop principal de 10 folds; e terceiro, implementar a seleção de K para o KNN. Para cada fold de 10, ele roda uma nova validação interna de 3 folds (somente no treino) para descobrir qual K (1, 3, 5, etc.) dá o melhor F1-Score, antes de treinar o modelo final daquele fold. Isso garante que não usamos o K ótimo no conjunto de teste."
(Fim)

3. Funcionamento dos Algoritmos (3-5 minutos)

Tópicos do Slide

KNN (K-Nearest Neighbors)

Conceito: "Lazy Learner" (Aprendiz Preguiçoso). Não aprende nada no fit, apenas memoriza.

fit(X, y): Apenas armazena X_treino e y_treino na memória. (Custo O(1)).

predict(X_teste):

Para cada ponto de teste, calcula a distância (Euclidiana ou Manhattan) para todos os pontos de treino. (Custo O(N_treino)).

Encontra os K vizinhos mais próximos.

Realiza uma "votação": a classe mais comum entre os K vizinhos vence.

(Nosso desempate: usa a classe majoritária do treino).

Bayesiano Univariado (Naive Bayes)

Conceito: Assume que todos os 4 atributos (variance, skewness...) são independentes.

fit(X, y): "Eager Learner". Calcula:

log(P(Classe)) (os Priors).

Para cada Classe e cada Atributo, calcula a Média (μ) e a Variância (σ²).

predict(X_teste): Encontra a classe que maximiza:

Score = log(Prior) + Σ log(PDF(x_i | μ_ci, σ²_ci))

(Soma dos logs das Fórmulas Gaussianas de cada atributo).

Bayesiano Multivariado

Conceito: Não assume independência. Modela a relação entre os atributos.

fit(X, y): Calcula:

log(P(Classe)) (os Priors).

Para cada Classe: Vetor de Média (μ) (4x1) e Matriz de Covariância (Σ) (4x4).

(Crucial: Adiciona regularização εI à diagonal de Σ para estabilidade).

predict(X_teste): Encontra a classe que maximiza:

Score = log(Prior) + log(PDF_Multi(x | μ_c, Σ_c))

(Usa a fórmula da Gaussiana Multivariada, baseada na inversa da covariância).

Notas do Apresentador (Roteiro)

(Início)
"Vamos revisar rapidamente como os três algoritmos que implementamos funcionam."

"O KNN é o mais simples. Ele é um 'lazy learner'. O fit dele é instantâneo: ele só memoriza os dados de treino. A parte cara é o predict. Para cada nova nota que queremos classificar, ele calcula a distância (Euclidiana ou Manhattan) até todas as 1200 notas que ele memorizou, pega as K mais próximas (ex: K=3), e faz uma votação. Se 2 vizinhos são 'Falsos' e 1 é 'Genuíno', a predição é 'Falso'."

"O Bayesiano Univariado é 'eager', ele aprende no fit. Ele assume que todos os atributos são independentes, o que é uma suposição 'ingênua' (Naive). No fit, ele calcula a média e a variância de cada atributo (variance, skewness, etc.) para cada classe (Genuína, Falsa). No predict, ele calcula um score somando a probabilidade de cada atributo pertencer a cada classe. A classe com maior score vence."

"Finalmente, o Bayesiano Multivariado é o mais avançado. Ele não assume independência. No fit, ele também calcula as médias, mas em vez de variâncias separadas, ele calcula uma Matriz de Covariância 4x4 para cada classe. Esta matriz captura como os atributos se relacionam (ex: como a 'curtose' muda quando a 'assimetria' muda). No predict, ele usa a fórmula da Gaussiana Multivariada, que é mais complexa e usa a inversa dessa matriz de covariância. O 'pulo do gato' aqui foi adicionar uma pequena regularização (epsilon) à diagonal da matriz para garantir que ela sempre pudesse ser invertida, o que foi essencial para o código funcionar."
(Fim)

4. Resultados (3-5 minutos)

Tópicos do Slide

Tabela de Resultados (10-Fold CV, sem normalização)

(Colar a Tabela Final gerada pelo main.py)
| Classificador | Acurácia | Precisão | F1-Score | Tempo Treino (s) | Tempo Teste (s) |
| :--- | :---: | :---: | :---: | :---: | :---: |
| KNN (Euclidiana) | 0.9993 ± 0.0022 | 0.9992 ± 0.0024 | 0.9993 ± 0.0022 | 0.00013 ± 0.00001 | 0.00631 ± 0.00045 |
| KNN (Manhattan) | 0.9993 ± 0.0022 | 0.9992 ± 0.0024 | 0.9993 ± 0.0022 | 0.00013 ± 0.00000 | 0.01027 ± 0.00075 |
| Bayesiano (Multivariado) | 0.9840 ± 0.0091 | 0.9828 ± 0.0096 | 0.9838 ± 0.0091 | 0.00034 ± 0.00006 | 0.00007 ± 0.00001 |
| Bayesiano (Univariado) | 0.8396 ± 0.0292 | 0.8405 ± 0.0280 | 0.8363 ± 0.0307 | 0.00019 ± 0.00002 | 0.00006 ± 0.00001 |

Análise das Métricas:

Grupo 1 (Perfeito): KNNs (99.93%)

Ambas as distâncias (com seleção de K) alcançaram desempenho quase perfeito.

Indica que o dataset é muito bem separado no espaço de atributos.

Grupo 2 (Excelente): Bayes Multivariado (98.4%)

Desempenho ótimo, mas visivelmente inferior ao KNN.

Sugere que a suposição de uma única Gaussiana por classe é boa, mas não perfeita.

Grupo 3 (Fraco): Bayes Univariado (84%)

Desempenho significativamente pior.

A diferença de 84% para 98.4% (do Multi) prova que a suposição "Naive" de independência dos atributos é falsa e prejudicial neste dataset.

Análise dos Tempos (O Trade-off):

Tempo de Treino: Bayes Multi é o mais lento (cálculo de inversa), KNN é o mais rápido (só memoriza).

Tempo de Teste (Predição): A história se inverte.

Bayes (Uni e Multi) são instantâneos (0.00007s), pois é só uma fórmula.

KNN é 100x mais lento (0.006s a 0.010s), pois precisa varrer todo o dataset de treino a cada predição.

Notas do Apresentador (Roteiro)

(Início)
"Aqui estão os resultados finais da nossa Validação Cruzada 10-fold. A tabela mostra a média e o desvio padrão de todas as métricas e tempos para os quatro classificadores."

"A primeira coisa que salta aos olhos é o desempenho. Temos três grupos claros. No topo, os KNNs, tanto Euclidiano quanto Manhattan, atingiram 99.93% de acurácia, F1 e precisão. É um resultado quase perfeito, com desvio padrão baixíssimo, mostrando que o modelo é extremamente estável."

"No segundo grupo, temos o Bayesiano Multivariado, com excelentes 98.4% de acurácia. Um ótimo resultado, mas que mostra que a fronteira de decisão que o KNN encontrou é um pouco melhor que a fronteira elíptica que o Bayes Multi assumiu."

"E, por último, o Bayesiano Univariado, com apenas 84% de acurácia. A diferença gritante entre 84% e 98.4% do Multivariado é a nossa prova mais clara: os atributos não são independentes. Ignorar a covariância, como o modelo Univariado faz, leva a um desempenho muito fraco."

"Mas a história muda quando olhamos os tempos. O Tempo de Treino é rápido para todos, mas o Tempo de Teste é o ponto crucial. Os modelos Bayesianos são instantâneos, levando menos de 0.0001 segundos para fazer uma predição, pois é só aplicar uma fórmula. O KNN, por outro lado, foi 100 vezes mais lento. O KNN (Manhattan) foi o mais lento de todos, levando 0.01 segundos por predição, pois ele precisa calcular a distância para todos os pontos de treino."
(Fim)

5. Conclusões (3-5 minutos)

Tópicos do Slide

Qual modelo teve o melhor desempenho?

O KNN (Euclidiana ou Manhattan) foi o vencedor claro em métricas (99.93%), provando que sua abordagem não-paramétrica foi a mais adequada para a fronteira de decisão deste dataset.

Qual modelo oferece o melhor equilíbrio (Desempenho vs. Eficiência)?

O Bayesiano Multivariado (98.4%).

Embora 1.5% menos preciso que o KNN, seu tempo de predição é 100 vezes mais rápido.

Em uma aplicação real (embarcada num caixa eletrônico), essa velocidade de predição é crucial, e 98.4% de acurácia é um resultado excelente.

Principal Lição Aprendida:

A suposição "Naive" de independência (Bayes Univariado) é perigosa. Validar essa suposição (comparando com o Multivariado) foi essencial.

Limitações e Trabalhos Futuros:

Normalização: Não usamos normalização (Z-score) na execução final. Um teste futuro seria rodar python main.py --normalizar para ver se isso afeta o KNN (embora com 99.9%, a melhoria seja improvável).

Outros Modelos: O desempenho do Bayes Multi sugere que modelos baseados em Gaussianas (como GMMs ou QDA) seriam muito eficazes.

Notas do Apresentador (Roteiro)

(Início)
"Para concluir, qual classificador venceu?"

"Se o único critério fosse a acurácia, o KNN é o vencedor indiscutível. Com 99.93%, ele modelou perfeitamente os dados. A seleção de K automática que implementamos funcionou muito bem, encontrando K=4 para Euclidiana e K=1 para Manhattan, em média."

"Porém, se a pergunta é qual modelo oferece o melhor equilíbrio para uma aplicação real, a minha conclusão muda. O Bayesiano Multivariado, com 98.4% de acurácia, é quase tão bom quanto o KNN, mas é cem vezes mais rápido na hora de classificar uma nota."

"Em um cenário onde a latência importa, como um caixa rápido, o Bayesiano Multivariado é a escolha de engenharia superior, pois oferece desempenho excelente com eficiência máxima."

"A principal lição deste trabalho foi ver, na prática, o custo de uma suposição errada. O modelo Naive Bayes (Univariado) falhou porque sua suposição central de independência dos atributos estava fundamentalmente errada para este problema."

"Como trabalhos futuros, o próximo passo seria re-executar o pipeline ativando a flag --normalizar. Embora o KNN já esteja em 99.9%, seria interessante ver se a normalização muda o K escolhido ou a estabilidade do modelo. Além disso, o sucesso do Bayes Multi sugere que outros modelos que assumem distribuições Gaussianas, como o QDA (Análise Discriminante Quadrática), também teriam um ótimo desempenho."

"Obrigado."
(Fim)